{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Einflussfaktoren auf Strompreis](https://blog.enviam.de/wp-content/uploads/2022/01/infografik_einflussfaktoren-auf-strompreis-1.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToDo:\n",
    "\n",
    "- [ ] CO_2 Preise hinzufügen\n",
    "- [ ] Gaspreise hinzufügen\n",
    "- [ ] Rohölpreise hinzufügen\n",
    "- [ ] Kohlepreise hinzufügen\n",
    "- [ ] Verbraucherverhalten hinzufügen (Jahreszeit, is_ferien_ja/nein)\n",
    "- [ ] Wir nutzen viel Gas in Deutschland, also auch Füllstand? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the absolute path to the `iTransformer/model` directory at the start of sys.path\n",
    "# sys.path.insert(0, os.path.abspath(\"iTransformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import numpy as np\n",
    "# from iTransformer.model.iTransformer import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define configuration settings\n",
    "# class Configs:\n",
    "#     def __init__(self):\n",
    "#         self.seq_len = 30          # Input sequence length (e.g., 30 days)\n",
    "#         self.pred_len = 7          # Prediction length (e.g., forecast next 7 days)\n",
    "#         self.d_model = 64          # Dimension of the model\n",
    "#         self.embed = 'timeF'       # Embedding type for time features\n",
    "#         self.freq = 'd'            # Daily frequency for electricity data\n",
    "#         self.dropout = 0.1         # Dropout rate\n",
    "#         self.e_layers = 2          # Number of encoder layers\n",
    "#         self.n_heads = 4           # Number of attention heads\n",
    "#         self.d_ff = 128            # Feedforward dimension\n",
    "#         self.activation = 'relu'   # Activation function\n",
    "#         self.output_attention = False\n",
    "#         self.use_norm = True\n",
    "#         self.class_strategy = None # Additional class settings (adjust as needed)\n",
    "#         self.factor = 5            # Scaling factor for attention (set according to model needs)\n",
    "\n",
    "\n",
    "# configs = Configs()\n",
    "\n",
    "# # Instantiate the model\n",
    "# model = Model(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dummy data preparation (replace with actual electricity price data)\n",
    "# batch_size = 1\n",
    "# n_features = 1  # For univariate data (single electricity price series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dummy data for input and timestamp embeddings\n",
    "# x_enc = torch.rand(batch_size, configs.seq_len, n_features)  # Encoder input\n",
    "# x_mark_enc = torch.rand(batch_size, configs.seq_len, n_features)  # Encoder timestamps\n",
    "# x_dec = torch.rand(batch_size, configs.pred_len, n_features)  # Decoder input\n",
    "# x_mark_dec = torch.rand(batch_size, configs.pred_len, n_features)  # Decoder timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Perform forecasting\n",
    "# model.eval()  # Set model to evaluation mode for inference\n",
    "# with torch.no_grad():\n",
    "#     output = model(x_enc, x_mark_enc, x_dec, x_mark_dec)\n",
    "\n",
    "# # Display forecasted values\n",
    "# print(\"Forecasted electricity prices:\", output.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try to fit a iTransformer on my data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             start_date             end_date  Germany/Luxembourg [€/MWh]\n",
      "0  Jan 1, 2024 12:00 AM  Jan 1, 2024 1:00 AM                        0.10\n",
      "1   Jan 1, 2024 1:00 AM  Jan 1, 2024 2:00 AM                        0.01\n",
      "2   Jan 1, 2024 2:00 AM  Jan 1, 2024 3:00 AM                        0.00\n",
      "3   Jan 1, 2024 3:00 AM  Jan 1, 2024 4:00 AM                       -0.01\n",
      "4   Jan 1, 2024 4:00 AM  Jan 1, 2024 5:00 AM                       -0.03\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "file_path = 'time_series_jan_feb.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Check the data structure\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\AppData\\Local\\Temp\\ipykernel_26300\\87859670.py:2: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['start_date'] = pd.to_datetime(df['start_date'])\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'timestamp' is the time column and 'price' is the target\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df = df.sort_values(by='start_date').reset_index(drop=True)\n",
    "\n",
    "# Extract just the hourly price data for simplicity\n",
    "prices = df['Germany/Luxembourg [€/MWh]'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['start_date'].dt.hour  # Hour of the day\n",
    "hours = df['hour'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Define sequences for the model\n",
    "seq_len = 24  # Input sequence length (last 24 hours)\n",
    "pred_len = 24  # Forecast length (next 24 hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences of input and output pairs\n",
    "x_data = []\n",
    "y_data = []\n",
    "for i in range(len(prices) - seq_len - pred_len):\n",
    "    x_prices = prices[i:i + seq_len]\n",
    "    x_hours = hours[i:i + seq_len]\n",
    "    \n",
    "    # Combine prices and hour features (e.g., as tuples or concatenated arrays)\n",
    "    x = [[price, hour] for price, hour in zip(x_prices, x_hours)]\n",
    "    \n",
    "    y = prices[i + seq_len:i + seq_len + pred_len]\n",
    "    x_data.append(x)\n",
    "    y_data.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays and then to tensors\n",
    "x_data = np.array(x_data)\n",
    "y_data = np.array(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = torch.tensor(x_data, dtype=torch.float32)\n",
    "y_data = torch.tensor(y_data, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape to match model requirements: [batch_size, seq_len, n_features]\n",
    "#x_data = x_data.unsqueeze(-1)  # Add a features dimension for univariate\n",
    "y_data = y_data.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1008, 24, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1008, 24, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the absolute path to the `iTransformer/model` directory at the start of sys.path\n",
    "sys.path.insert(0, os.path.abspath(\"iTransformer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'iTransformer.model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01miTransformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miTransformer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'iTransformer.model'"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from iTransformer.model.iTransformer import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define configuration settings\n",
    "class Configs:\n",
    "    def __init__(self):\n",
    "        self.seq_len = seq_len\n",
    "        self.pred_len = pred_len\n",
    "        self.d_model = 64\n",
    "        self.embed = 'timeF'\n",
    "        self.freq = 'h'            # Hourly frequency for data\n",
    "        self.dropout = 0.1\n",
    "        self.e_layers = 2\n",
    "        self.n_heads = 4\n",
    "        self.d_ff = 128\n",
    "        self.activation = 'relu'\n",
    "        self.output_attention = False\n",
    "        self.use_norm = True\n",
    "        self.class_strategy = None\n",
    "        self.factor = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = Configs()\n",
    "model = Model(configs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader for batching\n",
    "batch_size = 16\n",
    "train_dataset = TensorDataset(x_data, y_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "model.train()\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        # Forecast\n",
    "        output = model(x_batch, None, None, None)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference example (predict the next 24 hours)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    last_24_hours = torch.tensor(prices[-seq_len:], dtype=torch.float32).unsqueeze(0).unsqueeze(-1)\n",
    "    predicted_prices = model(last_24_hours, None, None, None)\n",
    "    print(\"Predicted prices for the next 24 hours:\", predicted_prices.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the validation data (assuming it’s in the same file for simplicity)\n",
    "file_path = 'validation_dataset.xlsx'\n",
    "validation_df = pd.read_excel(file_path)  # Adjust the sheet name if needed\n",
    "validation_df['start_date'] = pd.to_datetime(validation_df['start_date'])\n",
    "validation_df = validation_df.sort_values(by='start_date').reset_index(drop=True)\n",
    "validation_prices = validation_df['Germany/Luxembourg [€/MWh]'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the validation input sequence (last 24 hours for input)\n",
    "validation_input = validation_prices[:seq_len]  # Assuming we start with the initial sequence for forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_input = torch.tensor(validation_input, dtype=torch.float32).unsqueeze(0).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_values = np.array(validation_input).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = np.array(predicted_prices).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(actual_values)), actual_values, label=\"Actual Prices\", marker='o')\n",
    "plt.plot(range(len(predicted_values)), predicted_values, label=\"Predicted Prices\", marker='x')\n",
    "plt.xlabel(\"Hour\")\n",
    "plt.ylabel(\"Electricity Price\")\n",
    "plt.title(\"Predicted vs Actual Electricity Prices\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
